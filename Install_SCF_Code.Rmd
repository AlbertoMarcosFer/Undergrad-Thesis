---
title: "ajdamico1"
author: "Alberto Marcos Fernandez"
date: "2024-05-08"
output: html_document
---

The code below is an adaptation of Anthony Damico's (2014) work for datasets corresponding to editions more recent than the 2013 one (check the following url: <https://github.com/DjalmaPessoa/usgsd/blob/master/Survey%20of%20Consumer%20Finances/download%20all%20microdata.R>).

This code is meant to be used only once (the first time analyzing the SCF data). It downloads all the Survey of Consumer Finances editions and installs R packages needed for the statistical computations executed below. Since this process is computationally intensive, it is preferable to download all the necessary documents to perform the analyses later on.

Define a folder to be used as your working directory below inside setwd(). Please, make sure to use forward slashes (i.e., /) instead of backward slashes (i.e., \\).

```{r}
setwd( "WRITE YOUR DESIRED LOCATION HERE" )


years.to.download <- c(1989, 1992 , 1995, 1998 , 2001 , 2004 , 2007 , 2010 , 2013 , 2016 , 2019 , 2022)


install.packages( c( 'mitools' , 'survey' , 'downloader' , "foreign" , "dplyr" , "DescTools" , "tidyr" , "gglot2" , "car", "pander") )
library(downloader)
library(foreign)
library(haven)
library(mitools)
library(dplyr)
library(DescTools)
library(tidyr)
library(ggplot2)
library(car)
library(pander)

downloads <-
	data.frame(
		year = 
			c(1989, 1992 , 1995 , 1998 , 2001 , 2004 , 2007 , 2010  , 2013 , 2016 , 2019 , 2022 ) ,
		main = 
			c('scf89s', 'scf92s' , 'scf95s' , 'scf98s' , 'scf01s' , 'scf2004s' , 'scf2007s' , 'scf2010s' , 'scf2013s', 'scf2016s', 'scf2019s', 'scf2022s' ) ,
		extract = 
			c('scfp1989s', 'scfp1992s' , 'scfp1995s' , 'scfp1998s' , 'scfp2001s' , 'scfp2004s' , 'scfp2007s' , 'scfp2010s' , 'scfp2013s', 'scfp2016s' , 'scfp2019s' , 'scfp2022s'  ) ,
		rw = 
			c('scf89rw1s', 'scf92rw1s' , 'scf95rw1s' , 'scf98rw1s' , 'scf2001rw1s' , 'scf2004rw1s' , 'scf2007rw1s', 'scf2010rw1s' , 'scf2013rw1s', 'scf2016rw1s' , 'scf2019rw1s' , 'scf2022rw1s'  )
	)

	
# restrict the scf filename data frame to only years to download specified by the user above
downloads <- downloads[ downloads$year %in% years.to.download , ]


# initiate a function that..
read.scf <-
	# starts with the zipped file's filename (without `.zip`)
	# and the exact url path to that zipped file, then..
	function( zip.fn , http.path = "https://www.federalreserve.gov/econres/files/" ){
	
		# initiate a temporary file and temporary directory
		tf <- tempfile() ; td <- tempdir()

		# download the `.zip` file
		download.file(
			# ..using the url constructed from the function's inputs
			paste0( http.path , zip.fn , ".zip" ) ,
			# save this file into the temporary file on your local disk
			tf ,
			# use mode = writable + binary
			mode = 'wb'
		)

		# unzip the temporary file into the temporary directory,
		# and store the full file path of the unzipped file
		# into a new local file name (lfn) variable
		lfn <- unzip( tf , exdir = td )

		# read the stata file directly into memory
		x <- read_dta( lfn )

		# remove the temporary file and the unzipped file in the temporary directory
		file.remove( tf )
		file.remove( lfn )

		# have the function pass back just the data.frame object
		# (that is, just this specific data table)
		return( x )
	}


# loop through each record in the `downloads` table..
for ( i in seq( nrow( downloads ) ) ){
	
	# download and import the main data table
	scf.m <- read.scf( downloads[ i , 'main' ] )
	
	# download and import the extract data table
	scf.e <- read.scf( downloads[ i , 'extract' ] )
	
	# if downloading the 2001 file, the http path must be changed..
	if ( downloads[ i , 'year' ] == 2001 ){
	
		# read in the replicate weights file using the modified path
		rw <- 
			read.scf(
				downloads[ i , 'rw' ] ,
				http.path = "http://www.federalreserve.gov/pubs/oss/oss2/2001/"
			)
	
	# ..otherwise..
	} else {
	
		# read in the replicate weights file using the default path
		# (specified in the `read.scf` function initiation above)
		rw <- read.scf( downloads[ i , 'rw' ] ) 
		
	}
	
	
	names( scf.m ) <- tolower( names( scf.m ) )
	names( scf.e ) <- tolower( names( scf.e ) )
	names( rw ) <- tolower( names( rw ) )
	
	# the number of rows in the main file should exactly equal
	# the number of rows in the extract file
	stopifnot( nrow( scf.m ) == nrow( scf.e ) )
	
	
	# the 2007 replicate weights file has a goofy extra record for some reason..
	# ..so delete it manually.
	# if the current year being downloaded is 2007,
	# then overwrite the replicate weights table (rw)
	# with the same table, but missing unique id 1817
	# (which is the non-matching record)
	if ( downloads[ i , 'year' ] == 2007 ) rw <- rw[ !( rw$yy1 == 1817 ) , ]
	
	
	# the number of rows in the main file should exactly equal
	# the number of rows in the replicate weights file, times five
	if( nrow( scf.m ) != ( nrow( rw ) * 5 ) ){
		print( "the number of records in the main file doesn't equal five times the number in the rw file" )
		print( paste( 'scf.m rows:' , nrow( scf.m ) , " / rw rows:" , nrow( rw ) ) )
		stop( "this must be fixed before continuing." )
	}
	
	# the 1989 files contain unique identifiers `x1` and `xx1`
	# instead of `y1` and `yy1` .. change those two columns in all three data files.
	if ( downloads[ i , 'year' ] == 1989 ){
		names( scf.m )[ names( scf.m ) == 'x1' ] <- 'y1' ; names( scf.m )[ names( scf.m ) == 'xx1' ] <- 'yy1' ;
		names( scf.e )[ names( scf.e ) == 'x1' ] <- 'y1' ; names( scf.e )[ names( scf.e ) == 'xx1' ] <- 'yy1'
		names( rw )[ names( rw ) == 'x1' ] <- 'y1' ; names( rw )[ names( rw ) == 'xx1' ] <- 'yy1'
	}

	# confirm that the only overlapping columns
	# between the three data sets are `y1`
	# (the unique primary economic unit id - peu)
	# and `yy1` (the five records of the peu)
	stopifnot( all.equal( sort( intersect( names( scf.m ) , names( scf.e ) ) ) , c( 'y1' , 'yy1' ) ) )
	stopifnot( all.equal( sort( intersect( names( scf.m ) , names( rw ) ) ) , c( 'y1' , 'yy1' ) ) )
	stopifnot( all.equal( sort( intersect( names( scf.e ) , names( rw ) ) ) , c( 'y1' , 'yy1' ) ) )

	# throw out the unique identifiers ending with `1`
	# because they only match one-fifth of the records in the survey data
	rw$y1 <- NULL

	# `scf.m` currently contains
	# five records per household -- all five of the implicates.

	# add a column `one` to every record, containing just the number one
	scf.m$one <- 1
	
	# add a column `five` to every record, containing just the number five
	scf.m$five <- 5
	# note: this column should be used to calculate weighted totals.
	
	# break `scf.m` into five different data sets
	# based on the final character of the column 'y1'
	# which separates the five implicates
	scf.1 <- scf.m[ substr( scf.m$y1 , nchar( scf.m$y1 ) , nchar( scf.m$y1 ) ) == 1 , ]
	scf.2 <- scf.m[ substr( scf.m$y1 , nchar( scf.m$y1 ) , nchar( scf.m$y1 ) ) == 2 , ]
	scf.3 <- scf.m[ substr( scf.m$y1 , nchar( scf.m$y1 ) , nchar( scf.m$y1 ) ) == 3 , ]
	scf.4 <- scf.m[ substr( scf.m$y1 , nchar( scf.m$y1 ) , nchar( scf.m$y1 ) ) == 4 , ]
	scf.5 <- scf.m[ substr( scf.m$y1 , nchar( scf.m$y1 ) , nchar( scf.m$y1 ) ) == 5 , ]

	# count the total number of records in `scf.m`
	m.rows <- nrow( scf.m )
	
	# remove the main file from memory
	rm( scf.m )
	
	# clear up RAM
	gc()
	
	
	# merge the contents of the extract data frames
	# to each of the five implicates
	imp1 <- merge( scf.1 , scf.e )
	imp2 <- merge( scf.2 , scf.e )
	imp3 <- merge( scf.3 , scf.e )
	imp4 <- merge( scf.4 , scf.e )
	imp5 <- merge( scf.5 , scf.e )
	
	# remove the unmerged implicates from memory
	rm( scf.1 , scf.2 , scf.3 , scf.4 , scf.5 )
	
	# clear up RAM
	gc()
	
	# confirm that the number of records did not change
	stopifnot( 
		sum( nrow( imp1 ) , nrow( imp2 ) , nrow( imp3 ) , nrow( imp4 ) , nrow( imp5 ) ) == m.rows 
	)
	
	# throw out the `scf.e` data frame to free up RAM
	# for the next iteration of this loop
	rm( scf.e )
	
	# free up RAM
	gc()

	# sort all five implicates by the unique identifier
	imp1 <- imp1[ order( imp1$yy1 ) , ]
	imp2 <- imp2[ order( imp2$yy1 ) , ]
	imp3 <- imp3[ order( imp3$yy1 ) , ]
	imp4 <- imp4[ order( imp4$yy1 ) , ]
	imp5 <- imp5[ order( imp5$yy1 ) , ]
	
	
	# replace all missing values in the replicate weights table with zeroes..
	rw[ is.na( rw ) ] <- 0

	# ..then multiply the replicate weights by the multiplication factor
	rw[ , paste0( 'wgt' , 1:999 ) ] <- rw[ , paste0( 'wt1b' , 1:999 ) ] * rw[ , paste0( 'mm' , 1:999 ) ]

	# only keep the unique identifier and the final (combined) replicate weights
	rw <- rw[ , c( 'yy1' , paste0( 'wgt' , 1:999 ) ) ]
	
	# sort the replicate weights data frame by the unique identifier as well
	rw <- rw[ order( rw$yy1 ) , ]
	
	
	# pick an R data file (.rda) filename to save 
	# the final merged data frame `x` onto your local disk
	file.to.save <- paste0( 'scf' , downloads[ i , 'year' ] , '.rda' )

	
	# save the five implicates and the replicate weight file as that file name
	save( imp1 , imp2 , imp3 , imp4 , imp5 , rw , file = file.to.save )
	
	# throw out all data frames to free up RAM
	# for the next iteration of this loop
	rm( imp1 , imp2 , imp3 , imp4 , imp5 , rw )
	
	# free up RAM
	gc()
}
```
